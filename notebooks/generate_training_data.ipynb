{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Parrot\n",
    "\n",
    "---\n",
    "\n",
    "We want to investigate whether retraining Parrot can lead to improved results on smaller, single reaction class datasets. In this case we are going to use a pre-processed Suzuki reaction dataset which is a subset of USPTO-Condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import gdown\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the pre-trained and trained models into their required directories. Then we copy our Suzuki dataset which has been generated in a different repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gFV2KdVKaLCTeb3nrzopyYHXbM0G_cr_\n",
      "To: /home/mball/Documents/projects/parrot-verbose/outputs/best_uspto_condition.zip\n",
      "100%|██████████| 101M/101M [00:01<00:00, 97.2MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1bVB89ByGkYjiUtbvEcp1mgwmoKy5Ka2b\n",
      "To: /home/mball/Documents/projects/parrot-verbose/outputs/best_rcm_model_pretrain.zip\n",
      "100%|██████████| 72.4M/72.4M [00:00<00:00, 75.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DmHILXSOhUuAzqF0JmRTx1EcOOQ7Bm5O\n",
      "To: /home/mball/Documents/projects/parrot-verbose/outputs/best_mlm_model_pretrain.zip\n",
      "100%|██████████| 72.5M/72.5M [00:00<00:00, 77.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aX70qzZrJ9TZ9KpqnvUVR8WBxiTwXOsI\n",
      "To: /home/mball/Documents/projects/parrot-verbose/dataset/source_dataset/uspto_condition.zip\n",
      "100%|██████████| 536M/536M [00:22<00:00, 24.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "# import files using gdown:\n",
    "files_and_paths = [\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1gFV2KdVKaLCTeb3nrzopyYHXbM0G_cr_\",\n",
    "        \"../outputs/best_uspto_condition.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1bVB89ByGkYjiUtbvEcp1mgwmoKy5Ka2b\",\n",
    "        \"../outputs/best_rcm_model_pretrain.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1DmHILXSOhUuAzqF0JmRTx1EcOOQ7Bm5O\",\n",
    "        \"../outputs/best_mlm_model_pretrain.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1aX70qzZrJ9TZ9KpqnvUVR8WBxiTwXOsI\",\n",
    "        \"../dataset/source_dataset/uspto_condition.zip\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "for file, path in files_and_paths:\n",
    "    gdown.download(file, path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to ../outputs/best_uspto_condition\n",
      "Files extracted to ../outputs/best_rcm_model_pretrain\n",
      "Files extracted to ../outputs/best_mlm_model_pretrain\n"
     ]
    }
   ],
   "source": [
    "files_and_output_paths = [\n",
    "    [\n",
    "        \"../outputs/best_uspto_condition.zip\",\n",
    "        \"../outputs/best_uspto_condition\",\n",
    "    ],\n",
    "    [\n",
    "        \"../outputs/best_rcm_model_pretrain.zip\",\n",
    "        \"../outputs/best_rcm_model_pretrain\",\n",
    "    ],\n",
    "    [\n",
    "        \"../outputs/best_mlm_model_pretrain.zip\",\n",
    "        \"../outputs/best_mlm_model_pretrain\",\n",
    "    ],\n",
    "    [\n",
    "        \"../dataset/source_dataset/uspto_condition.zip\",\n",
    "        \"../dataset/source_dataset/uspto_condition\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "for zip_file_path, extract_to_path in files_and_output_paths:\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(extract_to_path, exist_ok=True)\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "\n",
    "    print(f\"Files extracted to {extract_to_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ../outputs/best_uspto_condition.zip\n",
      "Deleted ../outputs/best_rcm_model_pretrain.zip\n",
      "Deleted ../outputs/best_mlm_model_pretrain.zip\n"
     ]
    }
   ],
   "source": [
    "# Finally remove the zip files\n",
    "for zip_file_path, _ in files_and_output_paths:\n",
    "    os.remove(zip_file_path)\n",
    "    print(f\"Deleted {zip_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we inspect the Suzuki file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>source</th>\n",
       "      <th>dataset</th>\n",
       "      <th>rxn_category</th>\n",
       "      <th>rxn_class_name</th>\n",
       "      <th>remapped_rxn</th>\n",
       "      <th>rxn_centre_strs</th>\n",
       "      <th>rxn_id</th>\n",
       "      <th>valid_rxn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB1OB(C)OB(C)O1.Cc1cccc(Nc2nc(N[C@@H]3CCCC[C@@...</td>\n",
       "      <td>Cl[Pd]Cl</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US20110152273A1</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>Br[c:26]1[c:10]([NH:11][C@@H:12]2[CH2:13][CH2:...</td>\n",
       "      <td>[O;s&gt;s2&gt;2;][B;s&gt;s3&gt;2;]([O;s&gt;s2&gt;2;])[-&gt;.][C;s&gt;s...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nc1cnc(Br)cn1.OB(O)c1ccc(Br)cc1&gt;&gt;Nc1cnc(-c2ccc...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CCO</td>\n",
       "      <td>CCOC(C)=O</td>\n",
       "      <td>Cc1ccccc1</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td>US20140221311A1</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>Br[c:5]1[n:4][cH:3][c:2]([NH2:1])[n:14][cH:13]...</td>\n",
       "      <td>[O;s&gt;s1&gt;1;][B;s&gt;s3&gt;2;]([O;s&gt;s1&gt;1;])[-&gt;.][C;a&gt;a...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN1CCC(Oc2ccc(B3OC(C)(C)C(C)(C)O3)cc2)CC1.O=C(...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=C([O-])[O-].[Na+].[Na+]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US20140051679A1</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>CC1(C)OB([c:10]2[cH:9][cH:8][c:7]([O:6][CH:5]3...</td>\n",
       "      <td>[O;s&gt;s2&gt;2;][B;s&gt;s3&gt;2;]([O;s&gt;s2&gt;2;])[-&gt;.][C;a&gt;a...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       canonical_rxn  \\\n",
       "1  CB1OB(C)OB(C)O1.Cc1cccc(Nc2nc(N[C@@H]3CCCC[C@@...   \n",
       "2  Nc1cnc(Br)cn1.OB(O)c1ccc(Br)cc1>>Nc1cnc(-c2ccc...   \n",
       "3  CN1CCC(Oc2ccc(B3OC(C)(C)C(C)(C)O3)cc2)CC1.O=C(...   \n",
       "\n",
       "                                           catalyst1  solvent1   solvent2  \\\n",
       "1                                           Cl[Pd]Cl  C1COCCO1          O   \n",
       "2  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...       CCO  CCOC(C)=O   \n",
       "3  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...       CCO        NaN   \n",
       "\n",
       "                    reagent1                 reagent2           source  \\\n",
       "1    O=C([O-])[O-].[K+].[K+]                      NaN  US20110152273A1   \n",
       "2                  Cc1ccccc1  O=C([O-])[O-].[K+].[K+]  US20140221311A1   \n",
       "3  O=C([O-])[O-].[Na+].[Na+]                      NaN  US20140051679A1   \n",
       "\n",
       "  dataset  rxn_category   rxn_class_name  \\\n",
       "1   train           3.1  Suzuki coupling   \n",
       "2   train           3.1  Suzuki coupling   \n",
       "3   train           3.1  Suzuki coupling   \n",
       "\n",
       "                                        remapped_rxn  \\\n",
       "1  Br[c:26]1[c:10]([NH:11][C@@H:12]2[CH2:13][CH2:...   \n",
       "2  Br[c:5]1[n:4][cH:3][c:2]([NH2:1])[n:14][cH:13]...   \n",
       "3  CC1(C)OB([c:10]2[cH:9][cH:8][c:7]([O:6][CH:5]3...   \n",
       "\n",
       "                                     rxn_centre_strs  rxn_id  valid_rxn  \n",
       "1  [O;s>s2>2;][B;s>s3>2;]([O;s>s2>2;])[->.][C;s>s...       1       True  \n",
       "2  [O;s>s1>1;][B;s>s3>2;]([O;s>s1>1;])[->.][C;a>a...       2       True  \n",
       "3  [O;s>s2>2;][B;s>s3>2;]([O;s>s2>2;])[->.][C;a>a...       3       True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/source_dataset/suzuki/uspto_condition_suzuki_with_ids.csv\")\n",
    "cleaned_df = df[\n",
    "    (df[\"catalyst1\"].str.contains(\"Pd\")) & (df[\"rxn_centre_strs\"].str.contains(\"B;\"))\n",
    "]\n",
    "cleaned_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the raw dataset so that we can convert this dataset into a form that the model can be trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US20090239848A1</td>\n",
       "      <td>O=[N+]([O-])c1ccc(N2CCOCC2)cc1&gt;&gt;Nc1ccc(N2CCOCC...</td>\n",
       "      <td>[Zn]</td>\n",
       "      <td>C1CCOC1</td>\n",
       "      <td>O</td>\n",
       "      <td>CO</td>\n",
       "      <td>[Cl-].[NH4+]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                      canonical_rxn  \\\n",
       "0  US20090239848A1  O=[N+]([O-])c1ccc(N2CCOCC2)cc1>>Nc1ccc(N2CCOCC...   \n",
       "\n",
       "  catalyst1 solvent1 solvent2 reagent1      reagent2 dataset  \n",
       "0      [Zn]  C1CCOC1        O       CO  [Cl-].[NH4+]   train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uspto_ref_df = pd.read_csv(\n",
    "    \"/data1/mball/rcr-benchmark/datasets/uspto-condition/parrot/USPTO_condition.csv\"\n",
    ")\n",
    "uspto_ref_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the only columns that we need are the canonmical_rxn, reagents (cat, solv, reag) and dataset columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mball/miniforge3/envs/parrot_env/lib/python3.7/site-packages/pandas/core/frame.py:5182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20110152273A1</td>\n",
       "      <td>CB1OB(C)OB(C)O1.Cc1cccc(Nc2nc(N[C@@H]3CCCC[C@@...</td>\n",
       "      <td>Cl[Pd]Cl</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US20140221311A1</td>\n",
       "      <td>Nc1cnc(Br)cn1.OB(O)c1ccc(Br)cc1&gt;&gt;Nc1cnc(-c2ccc...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CCO</td>\n",
       "      <td>CCOC(C)=O</td>\n",
       "      <td>Cc1ccccc1</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US20140051679A1</td>\n",
       "      <td>CN1CCC(Oc2ccc(B3OC(C)(C)C(C)(C)O3)cc2)CC1.O=C(...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CCO</td>\n",
       "      <td></td>\n",
       "      <td>O=C([O-])[O-].[Na+].[Na+]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                      canonical_rxn  \\\n",
       "1  US20110152273A1  CB1OB(C)OB(C)O1.Cc1cccc(Nc2nc(N[C@@H]3CCCC[C@@...   \n",
       "2  US20140221311A1  Nc1cnc(Br)cn1.OB(O)c1ccc(Br)cc1>>Nc1cnc(-c2ccc...   \n",
       "3  US20140051679A1  CN1CCC(Oc2ccc(B3OC(C)(C)C(C)(C)O3)cc2)CC1.O=C(...   \n",
       "\n",
       "                                           catalyst1  solvent1   solvent2  \\\n",
       "1                                           Cl[Pd]Cl  C1COCCO1          O   \n",
       "2  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...       CCO  CCOC(C)=O   \n",
       "3  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...       CCO              \n",
       "\n",
       "                    reagent1                 reagent2 dataset  \n",
       "1    O=C([O-])[O-].[K+].[K+]                            train  \n",
       "2                  Cc1ccccc1  O=C([O-])[O-].[K+].[K+]   train  \n",
       "3  O=C([O-])[O-].[Na+].[Na+]                            train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suzuki_cleaned_df = cleaned_df[uspto_ref_df.columns]\n",
    "suzuki_cleaned_df.fillna(\"\", inplace=True)\n",
    "suzuki_cleaned_df.to_csv(\n",
    "    \"dataset/source_dataset/suzuki/suzuki_cleaned.csv\", index=False\n",
    ")\n",
    "suzuki_cleaned_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to write our config for the training:\n",
    "We are going to use the `configs/config_uspto_condition.yaml`, the only modifications are:\n",
    "\n",
    "- using the `outputs/Parrot_train_in_USPTO_Condition_enhance/Parrot_train_in_USPTO_Condition_enhance` for the pretrained_path\n",
    "- your choice of output directory\n",
    "- all other configs, including the model args are left the same\n",
    "\n",
    "Finally, we don't actually need the USPTO-condition dataset, but rather the idx.pkl file, which we copy over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/source_dataset/USPTO_condition_final'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_253625/3755891801.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/source_dataset/USPTO_condition_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/parrot_env/lib/python3.7/os.py\u001b[0m in \u001b[0;36mremovedirs\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/source_dataset/USPTO_condition_final'"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\n",
    "    \"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final/\"\n",
    "):\n",
    "    if not file.endswith(\".pkl\"):\n",
    "        os.remove(\n",
    "            f\"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final/{file}\"\n",
    "        )\n",
    "    elif file.endswith(\"labels.pkl\"):\n",
    "        os.remove(\n",
    "            f\"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final/{file}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Moving {file} to dataset/source_dataset/suzuki/\")\n",
    "        os.rename(\n",
    "            f\"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final/{file}\",\n",
    "            f\"dataset/source_dataset/suzuki/{file}\",\n",
    "        )\n",
    "\n",
    "os.removedirs(\"dataset/source_dataset/USPTO_condition_final/USPTO_condition_final\")\n",
    "os.removedirs(\"dataset/source_dataset/USPTO_condition_final\")\n",
    "\n",
    "os.remove(\"dataset/source_dataset/suzuki/USPTO_condition_alldata_idx.pkl\")\n",
    "\n",
    "# Finally we rename our desired idx file:\n",
    "os.rename(\n",
    "    \"dataset/source_dataset/suzuki/USPTO_condition_aug_n5_alldata_idx.pkl\",\n",
    "    \"dataset/source_dataset/suzuki/suzuki_cleaned_alldata_idx.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything else, we need to make one small adjustment to the best model config file. We change:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"processing_for_evaluation\": false,\n",
    "  \"use_early_stopping\": true\n",
    "}\n",
    "```\n",
    "\n",
    "IF we want to use early stopping.\n",
    "\n",
    "We need to generate the tokens for our data, which we can do by navigating into the `./preprocess_script/uspto_script` directory and running:\n",
    "\n",
    "```bash\n",
    "python 5.0.convert_context_tokens.py --source_data_path ../../dataset/source_dataset/ --dataset_dir_name dataset_dir --dataset_fname dataset_fname\n",
    "```\n",
    "\n",
    "We then train the model with\n",
    "\n",
    "```bash\n",
    "python train_parrot_model.py --gpu 0 --config_path configs/config_suzuki_retrain.yaml\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```bash\n",
    "python test_parrot_model.py --gpu 0 --config_path ./configs/config_test_suzuki_retrain.yaml --verbose\n",
    "```\n",
    "\n",
    "Where we then find the `suzuki_retrain_topk_accuracy.csv` and `verbose_output.csv` files in the checkpoint folder of the chosen model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parrot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
