{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data to Re-Train Parrot\n",
    "\n",
    "---\n",
    "\n",
    "We want to investigate whether retraining Parrot can lead to improved results on smaller, single reaction class datasets. In this case we are going to use a pre-processed Suzuki reaction dataset which is a subset of USPTO-Condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import gdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the pre-trained and trained models into their required directories. Then we copy our Suzuki dataset which has been generated in a different repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gFV2KdVKaLCTeb3nrzopyYHXbM0G_cr_\n",
      "To: /data1/mball/parrot-verbose/outputs/best_uspto_condition.zip\n",
      "100%|██████████| 101M/101M [00:01<00:00, 98.4MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1bVB89ByGkYjiUtbvEcp1mgwmoKy5Ka2b\n",
      "To: /data1/mball/parrot-verbose/outputs/best_rcm_model_pretrain.zip\n",
      "100%|██████████| 72.4M/72.4M [00:11<00:00, 6.07MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DmHILXSOhUuAzqF0JmRTx1EcOOQ7Bm5O\n",
      "To: /data1/mball/parrot-verbose/outputs/best_mlm_model_pretrain.zip\n",
      "100%|██████████| 72.5M/72.5M [00:00<00:00, 98.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aX70qzZrJ9TZ9KpqnvUVR8WBxiTwXOsI\n",
      "To: /data1/mball/parrot-verbose/dataset/source_dataset/uspto_condition.zip\n",
      "100%|██████████| 536M/536M [00:05<00:00, 94.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "# import files using gdown:\n",
    "files_and_paths = [\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1gFV2KdVKaLCTeb3nrzopyYHXbM0G_cr_\",\n",
    "        \"../outputs/best_uspto_condition.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1bVB89ByGkYjiUtbvEcp1mgwmoKy5Ka2b\",\n",
    "        \"../outputs/best_rcm_model_pretrain.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1DmHILXSOhUuAzqF0JmRTx1EcOOQ7Bm5O\",\n",
    "        \"../outputs/best_mlm_model_pretrain.zip\",\n",
    "    ],\n",
    "    [\n",
    "        \"https://drive.google.com/uc?id=1aX70qzZrJ9TZ9KpqnvUVR8WBxiTwXOsI\",\n",
    "        \"../dataset/source_dataset/uspto_condition.zip\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "for file, path in files_and_paths:\n",
    "    gdown.download(file, path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to ../outputs/best_uspto_condition\n",
      "Files extracted to ../outputs/best_rcm_model_pretrain\n",
      "Files extracted to ../outputs/best_mlm_model_pretrain\n",
      "Files extracted to ../dataset/source_dataset/uspto_condition\n"
     ]
    }
   ],
   "source": [
    "files_and_output_paths = [\n",
    "    [\n",
    "        \"../outputs/best_uspto_condition.zip\",\n",
    "        \"../outputs/best_uspto_condition\",\n",
    "    ],\n",
    "    [\n",
    "        \"../outputs/best_rcm_model_pretrain.zip\",\n",
    "        \"../outputs/best_rcm_model_pretrain\",\n",
    "    ],\n",
    "    [\n",
    "        \"../outputs/best_mlm_model_pretrain.zip\",\n",
    "        \"../outputs/best_mlm_model_pretrain\",\n",
    "    ],\n",
    "    [\n",
    "        \"../dataset/source_dataset/uspto_condition.zip\",\n",
    "        \"../dataset/source_dataset/uspto_condition\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "for zip_file_path, extract_to_path in files_and_output_paths:\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(extract_to_path, exist_ok=True)\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "\n",
    "    print(f\"Files extracted to {extract_to_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted ../outputs/best_uspto_condition.zip\n",
      "Deleted ../outputs/best_rcm_model_pretrain.zip\n",
      "Deleted ../outputs/best_mlm_model_pretrain.zip\n",
      "Deleted ../dataset/source_dataset/uspto_condition.zip\n"
     ]
    }
   ],
   "source": [
    "# Finally remove the zip files\n",
    "for zip_file_path, _ in files_and_output_paths:\n",
    "    os.remove(zip_file_path)\n",
    "    print(f\"Deleted {zip_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we inspect the Suzuki file, note that this has already been 'cleaned':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>dataset</th>\n",
       "      <th>rxn_category</th>\n",
       "      <th>rxn_class_name</th>\n",
       "      <th>remapped_rxn</th>\n",
       "      <th>rxn_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US20130190293A1</td>\n",
       "      <td>CC1(C)OB(c2ccc(O)nc2)OC1(C)C.Cc1ccc2c(c1)c1c(n...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>COCCOC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>Br[c:15]1[cH:14][cH:13][cH:12][c:11](-[n:10]2[...</td>\n",
       "      <td>8390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20100016368A1</td>\n",
       "      <td>C=C(C)B1OC(C)(C)C(C)(C)O1.CCOC(=O)Cn1ncc2c1CCC...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CN(C)C=O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Cl-].[NH4+]</td>\n",
       "      <td>CC(C)(C)[O-].[K+]</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>Br[c:4]1[cH:5][c:6]([C:7]([F:8])([F:9])[F:10])...</td>\n",
       "      <td>13508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US20140163009A1</td>\n",
       "      <td>CB1OB(C)OB(C)O1.COC(=O)[C@@H]1[C@H](c2ccccc2)[...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[Cs+].[Cs+]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suzuki coupling</td>\n",
       "      <td>Br[c:10]1[cH:9][cH:8][c:7]([C@H:6]2[C@H:5]([C:...</td>\n",
       "      <td>13901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                      canonical_rxn  \\\n",
       "0  US20130190293A1  CC1(C)OB(c2ccc(O)nc2)OC1(C)C.Cc1ccc2c(c1)c1c(n...   \n",
       "1  US20100016368A1  C=C(C)B1OC(C)(C)C(C)(C)O1.CCOC(=O)Cn1ncc2c1CCC...   \n",
       "2  US20140163009A1  CB1OB(C)OB(C)O1.COC(=O)[C@@H]1[C@H](c2ccccc2)[...   \n",
       "\n",
       "                                           catalyst1  solvent1 solvent2  \\\n",
       "0  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...    COCCOC      NaN   \n",
       "1  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...  CN(C)C=O      NaN   \n",
       "2  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...  C1COCCO1        O   \n",
       "\n",
       "                    reagent1                 reagent2 dataset  rxn_category  \\\n",
       "0                          O  O=C([O-])[O-].[K+].[K+]   train           3.1   \n",
       "1               [Cl-].[NH4+]        CC(C)(C)[O-].[K+]   train           3.1   \n",
       "2  O=C([O-])[O-].[Cs+].[Cs+]                      NaN   train           3.1   \n",
       "\n",
       "    rxn_class_name                                       remapped_rxn  rxn_id  \n",
       "0  Suzuki coupling  Br[c:15]1[cH:14][cH:13][cH:12][c:11](-[n:10]2[...    8390  \n",
       "1  Suzuki coupling  Br[c:4]1[cH:5][c:6]([C:7]([F:8])([F:9])[F:10])...   13508  \n",
       "2  Suzuki coupling  Br[c:10]1[cH:9][cH:8][c:7]([C@H:6]2[C@H:5]([C:...   13901  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this to set the name of the folder where the data will be saved\n",
    "folder_name = \"uspto_suzuki\"\n",
    "\n",
    "clean_df = pd.read_csv(\n",
    "    f\"../dataset/source_dataset/uspto_suzuki{folder_name}/uspto_condition_valid_suzuki_no_rc.csv\"\n",
    ")\n",
    "clean_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the raw dataset so that we can convert this dataset into a form that the model can be trained on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US20090239848A1</td>\n",
       "      <td>O=[N+]([O-])c1ccc(N2CCOCC2)cc1&gt;&gt;Nc1ccc(N2CCOCC...</td>\n",
       "      <td>[Zn]</td>\n",
       "      <td>C1CCOC1</td>\n",
       "      <td>O</td>\n",
       "      <td>CO</td>\n",
       "      <td>[Cl-].[NH4+]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                      canonical_rxn  \\\n",
       "0  US20090239848A1  O=[N+]([O-])c1ccc(N2CCOCC2)cc1>>Nc1ccc(N2CCOCC...   \n",
       "\n",
       "  catalyst1 solvent1 solvent2 reagent1      reagent2 dataset  \n",
       "0      [Zn]  C1CCOC1        O       CO  [Cl-].[NH4+]   train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uspto_ref_df = pd.read_csv(\n",
    "    \"../dataset/source_dataset/uspto_condition/USPTO_condition_final/USPTO_condition.csv\"\n",
    ")\n",
    "uspto_ref_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the only columns that we need are the canonical_rxn, reagents (cat, solv, reag) and dataset columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mball/miniforge3/envs/parrot_env/lib/python3.7/site-packages/pandas/core/frame.py:5182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>canonical_rxn</th>\n",
       "      <th>catalyst1</th>\n",
       "      <th>solvent1</th>\n",
       "      <th>solvent2</th>\n",
       "      <th>reagent1</th>\n",
       "      <th>reagent2</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US20130190293A1</td>\n",
       "      <td>CC1(C)OB(c2ccc(O)nc2)OC1(C)C.Cc1ccc2c(c1)c1c(n...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>COCCOC</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[K+].[K+]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US20100016368A1</td>\n",
       "      <td>C=C(C)B1OC(C)(C)C(C)(C)O1.CCOC(=O)Cn1ncc2c1CCC...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>CN(C)C=O</td>\n",
       "      <td></td>\n",
       "      <td>[Cl-].[NH4+]</td>\n",
       "      <td>CC(C)(C)[O-].[K+]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US20140163009A1</td>\n",
       "      <td>CB1OB(C)OB(C)O1.COC(=O)[C@@H]1[C@H](c2ccccc2)[...</td>\n",
       "      <td>c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...</td>\n",
       "      <td>C1COCCO1</td>\n",
       "      <td>O</td>\n",
       "      <td>O=C([O-])[O-].[Cs+].[Cs+]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                      canonical_rxn  \\\n",
       "0  US20130190293A1  CC1(C)OB(c2ccc(O)nc2)OC1(C)C.Cc1ccc2c(c1)c1c(n...   \n",
       "1  US20100016368A1  C=C(C)B1OC(C)(C)C(C)(C)O1.CCOC(=O)Cn1ncc2c1CCC...   \n",
       "2  US20140163009A1  CB1OB(C)OB(C)O1.COC(=O)[C@@H]1[C@H](c2ccccc2)[...   \n",
       "\n",
       "                                           catalyst1  solvent1 solvent2  \\\n",
       "0  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...    COCCOC            \n",
       "1  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...  CN(C)C=O            \n",
       "2  c1ccc([P](c2ccccc2)(c2ccccc2)[Pd]([P](c2ccccc2...  C1COCCO1        O   \n",
       "\n",
       "                    reagent1                 reagent2 dataset  \n",
       "0                          O  O=C([O-])[O-].[K+].[K+]   train  \n",
       "1               [Cl-].[NH4+]        CC(C)(C)[O-].[K+]   train  \n",
       "2  O=C([O-])[O-].[Cs+].[Cs+]                            train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suzuki_cleaned_df = clean_df[uspto_ref_df.columns]\n",
    "suzuki_cleaned_df.fillna(\"\", inplace=True)\n",
    "suzuki_cleaned_df.to_csv(\n",
    "    f\"../dataset/source_dataset/{folder_name}/suzuki_cleaned.csv\", index=False\n",
    ")\n",
    "suzuki_cleaned_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to write our config for the training:\n",
    "We are going to use the `configs/config_uspto_condition.yaml`, the only modifications are:\n",
    "\n",
    "- using the `outputs/Parrot_train_in_USPTO_Condition_enhance/Parrot_train_in_USPTO_Condition_enhance` for the pretrained_path\n",
    "- your choice of output directory\n",
    "- all other configs, including the model args are left the same\n",
    "\n",
    "Finally, we don't actually need the USPTO-condition dataset, but rather the idx.pkl file, which we copy over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving USPTO_condition_aug_n5_alldata_idx.pkl to dataset/source_dataset/suzuki_new/\n",
      "Moving USPTO_condition_alldata_idx.pkl to dataset/source_dataset/suzuki_new/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/source_dataset/uspto_condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_375298/3715115362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../dataset/source_dataset/uspto_condition/USPTO_condition_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../dataset/source_dataset/uspto_condition\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../dataset/source_dataset/{folder_name}/USPTO_condition_alldata_idx.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/parrot_env/lib/python3.7/os.py\u001b[0m in \u001b[0;36mremovedirs\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/source_dataset/uspto_condition'"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\n",
    "    \"../dataset/source_dataset/uspto_condition/USPTO_condition_final/\"\n",
    "):\n",
    "    if not file.endswith(\".pkl\"):\n",
    "        os.remove(\n",
    "            f\"../dataset/source_dataset/uspto_condition/USPTO_condition_final/{file}\"\n",
    "        )\n",
    "    elif file.endswith(\"labels.pkl\"):\n",
    "        os.remove(\n",
    "            f\"../dataset/source_dataset/uspto_condition/USPTO_condition_final/{file}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Moving {file} to dataset/source_dataset/{folder_name}/\")\n",
    "        os.rename(\n",
    "            f\"../dataset/source_dataset/uspto_condition/USPTO_condition_final/{file}\",\n",
    "            f\"../dataset/source_dataset/{folder_name}/{file}\",\n",
    "        )\n",
    "\n",
    "os.removedirs(\"../dataset/source_dataset/uspto_condition/USPTO_condition_final\")\n",
    "os.removedirs(\"../dataset/source_dataset/uspto_condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(f\"../dataset/source_dataset/{folder_name}/USPTO_condition_alldata_idx.pkl\")\n",
    "\n",
    "# Finally we rename our desired idx file:\n",
    "os.rename(\n",
    "    f\"../dataset/source_dataset/{folder_name}/USPTO_condition_aug_n5_alldata_idx.pkl\",\n",
    "    f\"../dataset/source_dataset/{folder_name}/suzuki_cleaned_alldata_idx.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything else, we need to make one small adjustment to the best model config file. This is NOT the config in /configs, but rather the `model_args.json` file in `outputs/best_uspto_condition` or `outputs/best_mlm_model_pretrain` We change:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"multiprocessing_for_evaluation\": false,\n",
    "  \"use_early_stopping\": false,\n",
    "  \"early_stopping_consider_epochs\": false,\n",
    "  \"evaluate_during_training_silent\": true,\n",
    "  \"evaluate_during_training_verbose\": false\n",
    "}\n",
    "```\n",
    "\n",
    "IF we want to use early stopping.\n",
    "\n",
    "We need to generate the tokens for our data, which we can do by navigating into the `./preprocess_script/uspto_script` directory and running:\n",
    "\n",
    "```bash\n",
    "python 5.0.convert_context_tokens.py --source_data_path ../../dataset/source_dataset/ --dataset_dir_name dataset_dir --dataset_fname dataset_fname --idx2data_fpath ../../dataset/source_dataset/{folder_name}/{file_name}_alldata_idx.pkl\n",
    "```\n",
    "\n",
    "We then train the model with\n",
    "\n",
    "```bash\n",
    "python train_parrot_model.py --gpu 0 --config_path configs/{config_name}.yaml\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```bash\n",
    "python test_parrot_model.py --gpu 0 --config_path ./configs/{test_config_name}.yaml --verbose\n",
    "```\n",
    "\n",
    "Where we then find the `suzuki_retrain_topk_accuracy.csv` and `verbose_output.csv` files in the checkpoint folder of the chosen model.\n",
    "\n",
    "Note that the config file for testing is different to training (since we are specifying a different trained model).\n",
    "\n",
    "You should find that your trained models (and checkpoints from each epoch) are under the /out folder. We take the best models as the model in this folder (the one produced after the final training epoch). All other models in these folders can be deleted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parrot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
